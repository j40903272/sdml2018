{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, \"/home/dada/jupyter/sdml/hw1/gae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "\n",
    "from gae.optimizer import OptimizerAE, OptimizerVAE\n",
    "from gae.input_data import load_data\n",
    "from gae.model import GCNModelAE, GCNModelVAE\n",
    "from gae.preprocessing import preprocess_graph, construct_feed_dict, sparse_to_tuple, mask_test_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting\n",
    "epochs = 200\n",
    "dropout = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_train = nx.read_edgelist('../../t1-train.txt', create_using=nx.DiGraph(), nodetype=int, edgetype=int)\n",
    "G_test_seen = nx.read_edgelist('../../t1-test-seen.txt', create_using=nx.DiGraph(), nodetype=int, edgetype=int)\n",
    "G_test = np.loadtxt('../../t1-test.txt')\n",
    "\n",
    "G = nx.DiGraph()\n",
    "#G.add_edges_from(G_train.edges)\n",
    "G.add_edges_from(G_test_seen.edges)\n",
    "nodes = [i for i in G.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = nx.adjacency_matrix(G)\n",
    "# Store original adjacency matrix (without diagonal entries) for later\n",
    "adj_orig = adj\n",
    "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "adj_orig.eliminate_zeros()\n",
    "\n",
    "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
    "adj = adj_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = sp.identity(adj.shape[0])  # featureless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some preprocessing\n",
    "adj_norm = preprocess_graph(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'features': tf.sparse_placeholder(tf.float32),\n",
    "    'adj': tf.sparse_placeholder(tf.float32),\n",
    "    'adj_orig': tf.sparse_placeholder(tf.float32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = adj.shape[0]\n",
    "features = sparse_to_tuple(features.tocoo())\n",
    "num_features = features[2][1]\n",
    "features_nonzero = features[1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gae.layers import GraphConvolution, GraphConvolutionSparse, InnerProductDecoder\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        allowed_kwargs = {'name', 'logging'}\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "        name = kwargs.get('name')\n",
    "        if not name:\n",
    "            name = self.__class__.__name__.lower()\n",
    "        self.name = name\n",
    "\n",
    "        logging = kwargs.get('logging', False)\n",
    "        self.logging = logging\n",
    "\n",
    "        self.vars = {}\n",
    "\n",
    "    def _build(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\" Wrapper for _build() \"\"\"\n",
    "        with tf.variable_scope(self.name):\n",
    "            self._build()\n",
    "        variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
    "        self.vars = {var.name: var for var in variables}\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    \n",
    "class GCNModelVAE(Model):\n",
    "    def __init__(self, placeholders, num_features, num_nodes, features_nonzero, **kwargs):\n",
    "        super(GCNModelVAE, self).__init__(**kwargs)\n",
    "\n",
    "        self.inputs = placeholders['features']\n",
    "        self.input_dim = num_features\n",
    "        self.features_nonzero = features_nonzero\n",
    "        self.n_samples = num_nodes\n",
    "        self.adj = placeholders['adj']\n",
    "        self.dropout = placeholders['dropout']\n",
    "        self.build()\n",
    "\n",
    "    def _build(self):\n",
    "        self.hidden1 = GraphConvolutionSparse(input_dim=self.input_dim,\n",
    "                                              output_dim=32,\n",
    "                                              adj=self.adj,\n",
    "                                              features_nonzero=self.features_nonzero,\n",
    "                                              act=tf.nn.relu,\n",
    "                                              dropout=self.dropout,\n",
    "                                              logging=self.logging)(self.inputs)\n",
    "\n",
    "        self.z_mean = GraphConvolution(input_dim=32,\n",
    "                                       output_dim=16,\n",
    "                                       adj=self.adj,\n",
    "                                       act=lambda x: x,\n",
    "                                       dropout=self.dropout,\n",
    "                                       logging=self.logging)(self.hidden1)\n",
    "\n",
    "        self.z_log_std = GraphConvolution(input_dim=32,\n",
    "                                          output_dim=16,\n",
    "                                          adj=self.adj,\n",
    "                                          act=lambda x: x,\n",
    "                                          dropout=self.dropout,\n",
    "                                          logging=self.logging)(self.hidden1)\n",
    "\n",
    "        self.z = self.z_mean + tf.random_normal([self.n_samples, 16]) * tf.exp(self.z_log_std)\n",
    "\n",
    "        self.reconstructions = InnerProductDecoder(input_dim=16,\n",
    "                                      act=lambda x: x,\n",
    "                                      logging=self.logging)(self.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCNModelVAE(placeholders, num_features, num_nodes, features_nonzero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerVAE(object):\n",
    "    def __init__(self, preds, labels, model, num_nodes, pos_weight, norm):\n",
    "        preds_sub = preds\n",
    "        labels_sub = labels\n",
    "\n",
    "        self.cost = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=0.01)  # Adam Optimizer\n",
    "\n",
    "        # Latent loss\n",
    "        self.log_lik = self.cost\n",
    "        self.kl = (0.5 / num_nodes) * tf.reduce_mean(tf.reduce_sum(1 + 2 * model.z_log_std - tf.square(model.z_mean) -\n",
    "                                                                   tf.square(tf.exp(model.z_log_std)), 1))\n",
    "        self.cost -= self.kl\n",
    "\n",
    "        self.opt_op = self.optimizer.minimize(self.cost)\n",
    "        self.grads_vars = self.optimizer.compute_gradients(self.cost)\n",
    "\n",
    "        self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n",
    "                                           tf.cast(labels_sub, tf.int32))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = OptimizerVAE(preds=model.reconstructions,\n",
    "                   labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                               validate_indices=False), [-1]),\n",
    "                   model=model, num_nodes=num_nodes,\n",
    "                   pos_weight=pos_weight,\n",
    "                   norm=norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_score(edges_pos, edges_neg, emb=None):\n",
    "    if emb is None:\n",
    "        feed_dict.update({placeholders['dropout']: 0})\n",
    "        emb = sess.run(model.z_mean, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    adj_rec = np.dot(emb, emb.T)\n",
    "    preds = []\n",
    "    pos = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        pos.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        neg.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds))])\n",
    "    \n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "    acc_score = accuracy_score(labels_all, preds_all)\n",
    "\n",
    "    return roc_score, ap_score, acc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
    "#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.3)\n",
    "sess = tf.Session()#config=tf.ConfigProto(gpu_options=gpu_options)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_val = []\n",
    "acc_val = []\n",
    "val_roc_score = []\n",
    "\n",
    "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "adj_label = sparse_to_tuple(adj_label)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: dropout})\n",
    "    # Run single weight update\n",
    "    outs = sess.run([opt.opt_op, opt.cost, opt.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "    # Compute average loss\n",
    "    avg_cost = outs[1]\n",
    "    avg_accuracy = outs[2]\n",
    "\n",
    "    roc_curr, ap_curr = get_roc_score(val_edges, val_edges_false)\n",
    "    val_roc_score.append(roc_curr)\n",
    "\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
    "          \"train_acc=\", \"{:.5f}\".format(avg_accuracy), \"val_roc=\", \"{:.5f}\".format(val_roc_score[-1]),\n",
    "          \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
    "          \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "roc_score, ap_score = get_roc_score(test_edges, test_edges_false)\n",
    "print('Test ROC score: ' + str(roc_score))\n",
    "print('Test AP score: ' + str(ap_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r GG\n",
    "%store -r all_deg_cent\n",
    "%store -r all_in_cent\n",
    "%store -r all_out_cent\n",
    "%store -r all_b_cent\n",
    "%store -r all_l_cent\n",
    "%store -r all_tri\n",
    "%store -r all_kc\n",
    "%store -r all_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feat(node):\n",
    "    feat = []\n",
    "    feat.append(GG.degree(node))\n",
    "    feat.append(GG.in_degree(node))\n",
    "    feat.append(GG.out_degree(node))\n",
    "    \n",
    "    feat.append(all_deg_cent[node] if node in all_deg_cent else 0)\n",
    "    feat.append(all_in_cent[node] if node in all_in_cent else 0)\n",
    "    feat.append(all_out_cent[node] if node in all_out_cent else 0)\n",
    "    feat.append(all_b_cent[node] if node in all_b_cent else 0)\n",
    "    feat.append(all_l_cent[node] if node in all_l_cent else 0)\n",
    "\n",
    "    feat.append(all_tri[node] if node in all_tri else 0)\n",
    "    feat.append(all_kc[node] if node in all_kc else 0)\n",
    "    feat.append(all_page[node] if node in all_page else 0)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_feat = {}\n",
    "for node in GG.nodes:\n",
    "    node_feat[node] = extract_feat(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29402"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('node_feat_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(node_feat, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
