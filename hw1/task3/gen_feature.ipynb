{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import re\n",
    "from sklearn.preprocessing import scale\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nodeMeta.pkl\", 'rb') as f:\n",
    "    nodeMeta = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169941, 2) (169941,)\n"
     ]
    }
   ],
   "source": [
    "prefix = \"4step_\"\n",
    "df = pd.read_csv(prefix+\"sample.csv\")\n",
    "X = np.squeeze(np.dstack([df['head'].values, df['tail'].values]))\n",
    "Y = df['label'].values\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "for fromId, toId in np.loadtxt('t3-test.txt'):\n",
    "    test_x.append((fromId,  toId))\n",
    "test_x = np.array(test_x).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"4step_\"\n",
    "with open(prefix+'feat.pkl', 'rb') as f:\n",
    "    feat = pickle.load(f)\n",
    "with open(prefix+'test_f.pkl', 'rb') as f:\n",
    "    test_f = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "test_f = []\n",
    "for h, t in test_x:\n",
    "    hemb = np.hstack([nodeMeta[h][\"tvec\"], nodeMeta[h][\"avec\"]])\n",
    "    temb = np.hstack([nodeMeta[t][\"tvec\"], nodeMeta[t][\"avec\"]])\n",
    "    test_f.append(np.hstack([hemb, temb]))\n",
    "test_f = np.array(test_f)\n",
    "print(test_f.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feat = []\n",
    "for h, t in X:\n",
    "    hemb = np.hstack([nodeMeta[h][\"tvec\"], nodeMeta[h][\"avec\"]])\n",
    "    temb = np.hstack([nodeMeta[t][\"tvec\"], nodeMeta[t][\"avec\"]])\n",
    "    feat.append(np.hstack([hemb, temb]))\n",
    "feat = np.array(feat)\n",
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extra features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(s):\n",
    "    width = 3\n",
    "    s = s.lower()\n",
    "    return [s[i:i+width] for i in range(max(len(s)-width+1, 1))]\n",
    "\n",
    "def add_time_sim_feat(h, t):\n",
    "    cos1 = cosine(nodeMeta[h][\"tvec\"], nodeMeta[t][\"tvec\"])\n",
    "    cos2 = cosine(nodeMeta[h][\"avec\"], nodeMeta[t][\"avec\"])\n",
    "    delta = (nodeMeta[t]['date'] - nodeMeta[h]['date']).days\n",
    "    time1 = [nodeMeta[t]['date'].day, nodeMeta[t]['date'].month, nodeMeta[t]['date'].year]\n",
    "    time2 = [nodeMeta[h]['date'].day, nodeMeta[h]['date'].month, nodeMeta[h]['date'].year]\n",
    "    \n",
    "    s1, s2 = set(nodeMeta[h]['title']), set(nodeMeta[t]['title'])\n",
    "    jaccard1 = float(len(s1.intersection(s2)))/float(len(s1.union(s2)))\n",
    "    s1, s2 = set(nodeMeta[h]['abstract']), set(nodeMeta[t]['abstract'])\n",
    "    jaccard2 = float(len(s1.intersection(s2)))/float(len(s1.union(s2)))\n",
    "    \n",
    "#     a = get_features(\" \".join(nodeMeta[h]['title']))\n",
    "#     b = get_features(\" \".join(nodeMeta[t]['abstract']))\n",
    "#     ham_dist1 = Simhash(a).distance(Simhash(b))\n",
    "#     a = get_features(\" \".join(nodeMeta[h]['title']))\n",
    "#     b = get_features(\" \".join(nodeMeta[t]['abstract']))\n",
    "#     ham_dist2 = Simhash(a).distance(Simhash(b))\n",
    "    \n",
    "    return [cos1, cos2, delta, jaccard1, jaccard2] + time1 + time2# + [ham_dist1, ham_dist2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from\n",
      "3246 from node\n",
      "0.0046210720887245845 in train\n",
      "to\n",
      "9213 to node\n",
      "0.7761858243785955 in train\n",
      "CPU times: user 6min 17s, sys: 120 ms, total: 6min 17s\n",
      "Wall time: 6min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "G_train = nx.read_edgelist('t3-train.txt', create_using=nx.DiGraph(), nodetype=int, edgetype=int)\n",
    "G_test = nx.read_edgelist('t3-test.txt', create_using=nx.DiGraph(), nodetype=int, edgetype=int)\n",
    "unG_train = nx.read_edgelist('t3-train.txt', create_using=nx.Graph(), nodetype=int, edgetype=int)\n",
    "unG_test = nx.read_edgelist('t3-test.txt', create_using=nx.Graph(), nodetype=int, edgetype=int)\n",
    "\n",
    "# check\n",
    "from_node = set()\n",
    "to_node = set()\n",
    "for i in G_test.edges:\n",
    "    from_node.add(i[0])\n",
    "    to_node.add(i[1])\n",
    "\n",
    "print(\"from\")\n",
    "print(len(from_node), \"from node\")\n",
    "print(len(from_node & set(G_train.nodes))/len(from_node), \"in train\")\n",
    "print(\"to\")\n",
    "print(len(to_node), \"to node\")\n",
    "print(len(to_node & set(G_train.nodes))/len(to_node), \"in train\")\n",
    "\n",
    "# compute\n",
    "deg_cent = nx.degree_centrality(G_train)\n",
    "in_cent = nx.in_degree_centrality(G_train)\n",
    "out_cent = nx.out_degree_centrality(G_train)\n",
    "b_cent = nx.betweenness_centrality(G_train)\n",
    "l_cent = nx.load_centrality(G_train)\n",
    "tri = nx.triangles(unG_train)\n",
    "kc = nx.katz_centrality(G_train)\n",
    "page = nx.pagerank(G_train)\n",
    "\n",
    "\n",
    "#store\n",
    "with open(\"deg_cent.pkl\", 'wb') as f:\n",
    "    pickle.dump(deg_cent, f)\n",
    "with open(\"in_cent.pkl\", 'wb') as f:\n",
    "    pickle.dump(in_cent, f)\n",
    "with open(\"out_cent.pkl\", 'wb') as f:\n",
    "    pickle.dump(out_cent, f)\n",
    "with open(\"b_cent.pkl\", 'wb') as f:\n",
    "    pickle.dump(b_cent, f)\n",
    "with open(\"l_cent.pkl\", 'wb') as f:\n",
    "    pickle.dump(l_cent, f)\n",
    "with open(\"tri.pkl\", 'wb') as f:\n",
    "    pickle.dump(tri, f)\n",
    "with open(\"kc.pkl\", 'wb') as f:\n",
    "    pickle.dump(kc, f)\n",
    "with open(\"page.pkl\", 'wb') as f:\n",
    "    pickle.dump(page, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"deg_cent.pkl\", 'rb') as f:\n",
    "    deg_cent = pickle.load(f)\n",
    "with open(\"in_cent.pkl\", 'rb') as f:\n",
    "    in_cent = pickle.load(f)\n",
    "with open(\"out_cent.pkl\", 'rb') as f:\n",
    "    out_cent = pickle.load(f)\n",
    "with open(\"b_cent.pkl\", 'rb') as f:\n",
    "    b_cent = pickle.load(f)\n",
    "with open(\"l_cent.pkl\", 'rb') as f:\n",
    "    l_cent = pickle.load(f)\n",
    "with open(\"tri.pkl\", 'rb') as f:\n",
    "    tri = pickle.load(f)\n",
    "with open(\"kc.pkl\", 'rb') as f:\n",
    "    kc = pickle.load(f)\n",
    "with open(\"page.pkl\", 'rb') as f:\n",
    "    page = pickle.load(f)\n",
    "\n",
    "# add only to_node\n",
    "def add_node_feature(h, t):\n",
    "    #feat = list(embedding[node])\n",
    "    feat = []\n",
    "    feat.append(G_train.degree(t) if t in G_train.nodes else 0)\n",
    "    feat.append(G_train.in_degree(t) if t in G_train.nodes else 0)\n",
    "    feat.append(G_train.out_degree(t) if t in G_train.nodes else 0)\n",
    "    \n",
    "    feat.append(deg_cent[t] if t in deg_cent else 0)\n",
    "    feat.append(in_cent[t] if t in in_cent else 0)\n",
    "    feat.append(out_cent[t] if t in out_cent else 0)\n",
    "    feat.append(b_cent[t] if t in b_cent else 0)\n",
    "    feat.append(l_cent[t] if t in l_cent else 0)\n",
    "    feat.append(tri[t]  if t in tri else 0)\n",
    "    feat.append(kc[t]  if t in kc else 0)\n",
    "    feat.append(page[t]  if t in page else 0)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute(idx1, idx2, org, f):\n",
    "    assert f.shape[1] == (idx2-idx1+1)\n",
    "    assert f.shape[0] == org.shape[0]\n",
    "    org[:, idx1:idx2+1] = f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244739, 11)\n"
     ]
    }
   ],
   "source": [
    "##################\n",
    "extract_feat = add_node_feature\n",
    "##################\n",
    "\n",
    "extra_feat = []\n",
    "for h, t in test_x:\n",
    "    extra_feat.append(extract_feat(h, t))\n",
    "\n",
    "for h, t in X:\n",
    "    extra_feat.append(extract_feat(h, t))\n",
    "\n",
    "extra_feat = scale(np.array(extra_feat))\n",
    "print(extra_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74798, 1624) (169941, 1624)\n"
     ]
    }
   ],
   "source": [
    "test_f = np.hstack([test_f, extra_feat[:len(test_x)]])\n",
    "feat = np.hstack([feat, extra_feat[len(test_x):]])\n",
    "print(test_f.shape, feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"4step_\"\n",
    "with open(prefix+'feat.pkl', 'wb') as f:\n",
    "    pickle.dump(feat, f)\n",
    "with open(prefix+'test_f.pkl', 'wb') as f:\n",
    "    pickle.dump(test_f, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
