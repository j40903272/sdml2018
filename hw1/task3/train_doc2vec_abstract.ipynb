{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('nodeMeta.pkl', 'rb') as f:\n",
    "    nodeMeta = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "              yield gensim.models.doc2vec.TaggedDocument(doc, [self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [nodeMeta[i]['abstract'] for i in nodeMeta]\n",
    "docLabels = list(range(len(corpus)))\n",
    "it = LabeledLineSentence(corpus, docLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(size=100, min_count=1, alpha=0.025, min_alpha=0.00025, workers=8, negative=5)\n",
    "model.build_vocab(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32min 38s, sys: 3min 37s, total: 36min 15s\n",
      "Wall time: 16min 17s\n"
     ]
    }
   ],
   "source": [
    "%time model.train(it, total_examples=model.corpus_count, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "train_corpus = list(it)\n",
    "\n",
    "for doc_id in range(model.corpus_count):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=50)\n",
    "    try:\n",
    "        rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    except:\n",
    "        rank = 100\n",
    "    ranks.append(rank)\n",
    "    \n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 16827,\n",
       "         1: 209,\n",
       "         2: 83,\n",
       "         3: 56,\n",
       "         4: 42,\n",
       "         5: 34,\n",
       "         6: 33,\n",
       "         7: 25,\n",
       "         8: 15,\n",
       "         9: 11,\n",
       "         10: 15,\n",
       "         11: 15,\n",
       "         12: 13,\n",
       "         13: 11,\n",
       "         14: 6,\n",
       "         15: 11,\n",
       "         16: 15,\n",
       "         17: 6,\n",
       "         18: 12,\n",
       "         19: 5,\n",
       "         20: 4,\n",
       "         21: 3,\n",
       "         22: 1,\n",
       "         24: 2,\n",
       "         25: 4,\n",
       "         26: 4,\n",
       "         27: 1,\n",
       "         28: 1,\n",
       "         29: 1,\n",
       "         30: 2,\n",
       "         31: 1,\n",
       "         32: 1,\n",
       "         35: 2,\n",
       "         36: 2,\n",
       "         39: 1,\n",
       "         41: 1,\n",
       "         46: 1,\n",
       "         47: 1,\n",
       "         48: 1,\n",
       "         54: 1,\n",
       "         57: 2,\n",
       "         61: 1,\n",
       "         64: 1,\n",
       "         72: 1,\n",
       "         74: 2,\n",
       "         85: 1,\n",
       "         88: 2,\n",
       "         100: 11})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 16827,\n",
       "         1: 209,\n",
       "         2: 83,\n",
       "         3: 56,\n",
       "         4: 42,\n",
       "         5: 34,\n",
       "         6: 33,\n",
       "         7: 25,\n",
       "         8: 15,\n",
       "         9: 11,\n",
       "         10: 15,\n",
       "         11: 15,\n",
       "         12: 13,\n",
       "         13: 11,\n",
       "         14: 6,\n",
       "         15: 11,\n",
       "         16: 15,\n",
       "         17: 6,\n",
       "         18: 12,\n",
       "         19: 5,\n",
       "         20: 4,\n",
       "         21: 3,\n",
       "         22: 1,\n",
       "         24: 2,\n",
       "         25: 4,\n",
       "         26: 4,\n",
       "         27: 1,\n",
       "         28: 1,\n",
       "         29: 1,\n",
       "         30: 2,\n",
       "         31: 1,\n",
       "         32: 1,\n",
       "         35: 2,\n",
       "         36: 2,\n",
       "         39: 1,\n",
       "         41: 1,\n",
       "         46: 1,\n",
       "         47: 1,\n",
       "         48: 1,\n",
       "         54: 1,\n",
       "         57: 2,\n",
       "         61: 1,\n",
       "         64: 1,\n",
       "         72: 1,\n",
       "         74: 2,\n",
       "         85: 1,\n",
       "         88: 2,\n",
       "         100: 11})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (17499): «derive explicit expression associative star product non commutative versions complex grassmannian spaces particular case complex 2 planes expression terms finite sum derivatives generalises previous results complex projective spaces gives discrete approximation grassmannians terms non commutative algebra represented matrix multiplication finite dimensional matrix algebra matrices restricted dimension precisely determined harmonic expansion functions commutative grassmannian truncated finite level limit infinite dimensional matrices recover commutative algebra functions complex grassmannians»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d100,n5,w5,s0.001,t8):\n",
      "\n",
      "MOST (17499, 0.7252527475357056): «derive explicit expression associative star product non commutative versions complex grassmannian spaces particular case complex 2 planes expression terms finite sum derivatives generalises previous results complex projective spaces gives discrete approximation grassmannians terms non commutative algebra represented matrix multiplication finite dimensional matrix algebra matrices restricted dimension precisely determined harmonic expansion functions commutative grassmannian truncated finite level limit infinite dimensional matrices recover commutative algebra functions complex grassmannians»\n",
      "\n",
      "SECOND-MOST (9213, 0.5644440054893494): «zero modes chiral su n wznw model give rise intertwining quantum matrix algebra generated n x n matrix i_ alpha noncommuting entries rational functions n commuting elements q p_i study generalization fock space f representation generic q q root unity demonstrate gives rise model quantum universal enveloping algebra u_q sl_n irreducible representation entering f multiplicity 1 integer level k complex parameter q even root unity q h 1 h k n algebra ideal i_h factor algebra a_h i_h finite dimensional»\n",
      "\n",
      "MEDIAN (13861, 0.45721274614334106): «construct realization yangian double dy_ hbar gl_n dy_ hbar sl_n arbitrary level k terms free boson fields continuous parameter hbar 0 limit realization becomes wakimoto realization kac moody algebra gl_n sl_n respectively vertex operators screening currents also constructed spirits screening currents commute dy_ hbar sl_n modulo total difference»\n",
      "\n",
      "LEAST (14456, 0.4350321888923645): «comments starting paper hep th 0106074 point unclear motivation definitions noncommutative momentum introduced therefore give clear presentation paper withdrawn»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.save(\"abstract_model.bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
